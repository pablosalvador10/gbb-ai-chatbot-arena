# Chatbot Arena

Welcome to the Chatbot Arena! Dive into the forefront of chatbot innovation with us as we embark on hands-on comparisons, rigorous testing, and comprehensive evaluations of Retrieval-Augmented Generation (RAG) patterns. Our quest is to elevate performance, from the nuances of information retrieval to the pinnacle of user experience, including the strategic selection of LLMs (Large Language Models) and SLMs (Small Language Models).

## ðŸ¤– Challenges in LLM/SLM Evaluation

Evaluating LLMs and SLMs presents unique challenges, including the need for continuous evaluation, adherence to responsible AI practices, and the tailoring of evaluation metrics to specific applications. Prompt Flow addresses these challenges by offering:

- **Continuous Integration, Evaluation, and Deployment (CI/CE/CD)**: Implementing LLMOps for effective lifecycle management.
- **Responsible AI Practices**: Ensuring ethical use and mitigating potential risks.
- **Tailored Evaluation Metrics**: Customizing metrics for meaningful assessments.

## ðŸ“‹ Table of Contents

This project provides multiple patterns to build chatbots and examines best practices, tips, and tricks. We will use Azure AI Document Intelligence to scan multiple formats and complex layout documents, perform semantic chunking, and index the data into Azure AI Search for state-of-the-art retrieval capabilities. Finally, we will use GPT-4 for retrieving the information.

### Disclaimer
> [!IMPORTANT]
> This software is provided for demonstration purposes only. It is not intended to be relied upon for any purpose. The creators of this software make no representations or warranties of any kind, express or implied, about the completeness, accuracy, reliability, suitability or availability with respect to the software or the information, products, services, or related graphics contained in the software for any purpose. Any reliance you place on such information is therefore strictly at your own risk.